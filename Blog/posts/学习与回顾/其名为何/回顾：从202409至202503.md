---
title: 回顾：从202409至202503
date: 2025-03-13
tags: [回顾,探索]
category: 原创 
pinned: true
---

# 2024年8月22日

出于对文件环境的洁癖，找遍了网上大部分的沙盒与虚拟机产品(虽然不知道为什么，但是我的电脑居然无法运行VMWare)，最终选择了SandBoxie_Plus，然后将各大网盘、各大盗版软件以及鹅厂的全部应用都丢到了沙盒中，实现了文件的整洁。

# 2024年8月底至9月初

刚入学的时候由于对DevCpp过于朴实的界面的厌弃以及对VisualSudio过于庞大的体积，选择了(当时认为是轻量级的)VSCode，随后开始了疯狂的插件安装。跟随B站以及知乎上的一些教程( [比如说这个](https://blog.csdn.net/m0_62721576/article/details/127207028) )，耗费了将近大半天的时间进行环境的配置，还花了数天的时间进行后续问题的解决。但是尽管如此我发现VSCode在运行C语言程序的时候还是过于不便了……

# 2024年9月7日

装回了我已经大半年没有用过的Anaconda(其实是因为Docker还是不会用)，再次想要编写一些Python程序，于是就简单写了几个爬取B站视频的自用程以及UI。

# 2024年10月9日

想要在自己这台电脑上重新使用OpenAI的Whisper模型，于是重装了FFmpeg和CUDA，pytorch的安装比两年前方便很多，但是失算的是，CUDA版本过高导致Whisper无法使用GPU运行，导致探索搁浅，虽然后面发现了[faster-whisper-GUI](https://github.com/CheshireCC/faster-whisper-GUI)这个项目。

# 2024年10月26日

由于自己的笔记大部分都以Markdown的格式呈现，所以希望能够方便的转换为其他格式，于是发现了pandoc，结合了Typora实现了Markdown自由。

# 2024年10月20日

第一次英语小组任务，为了做出视觉效果更加精彩的视频演示，耗费近四天来学习Adobe Animate的动画制作，虽然最后被英语老师说“喧宾夺主”，但是效果确实达到了预期。

# 2024年11月1日

借着科学思维课程这个契机进行了机器学习的探索，初步学习了随机游走、随机森林等算法，并重新开始使用我原本觉得没什么用的JupyterNotebook。虽然学的很浅显，但是感觉收获颇丰，至少学会了论文排版(在这之后5个月后又想要把西瓜书找出来从头开始正式的学一遍了)。

# 2024年11月11日

为了实现在不带电脑的情况下获得操作电脑的便利，我试图在我的安卓系平板上安装Linux。最初采用了AI特化的AidLUX，但是很遗憾，不知道是什么原因出现了很多的Glitch(我严重怀疑是鸿蒙4版本过高导致的不兼容，因为在我另一台鸿蒙2设备上完全正常)。后来也是在Github冲浪的时候发现了[tiny_computer](https://github.com/Cateners/tiny_computer)这个项目，成功安装了Debian12的虚拟机，获得了Linux系统下的纯净的QQ与WPS体验。不过后期发现蓝牙鼠标的滚轮在ANVC和noVNC中出现失灵情况，后采用Termux X11解决了此问题。

# 2024年11月23日

学习了一段时间的OpenCV，恰好在Github上冲浪的时候发现了一个名为ZZZAuto的库(虽然现在作者好像已经删库跑路了)，然后用Python也搞了一个类似的外挂应用(虽然很多代码是借鉴的)，比较简陋，只是达到了勉强能用的地步。

# 2024年12月7日

当时政治小组任务刚好需要拍视频，我被分配到了配音的工作，于是想要尝试三年前搞过的MockingBird的TTS项目和基于CircleGAN的语音转换，不过在高强度的Github冲浪之后，我发现了[GPT_SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)与[Retrieval-based-Voice-Conversion](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)，经过了极为痛苦的耗时几乎一整天的手动环境配置(到现在我还是不明白为什么明明提供了一键包，我还是要手动配环境，也许是纯粹喜欢配环境？)，成功完成了任务。

# 2024年12月10日

由于当时正在尝试阅读文献，希望找到一种能够高效了解文献主要内容的工具，于是在GitHub上找到了这个名为[gpt_academic](https://github.com/binary-husky/gpt_academic)的项目，本地部署后发现确实好用，功能与插件都非常丰富，但是费API。

# 2025年1月1日

不满足于在平板上使用Linux，于是试图在电脑上尝试，由于无法使用VMWare之类的虚拟机且双系统的安装难度对与当时的我而言有点高，因此选择了Windows系统自带的WSL2，参照了[B站上的教程](https://www.bilibili.com/video/BV1tW42197za)先后安装了Debian12和Ubuntu22.04进行测试，学习了相关语法。

# 2025年1月5日

由于向学校申请了VPN，但是发现使用的软件是深信服开发的EasyConnect，出于戒备，选择现学Docker，根据[相关教程](https://zhuanlan.zhihu.com/p/604247063)成功进行了配置，并学习了dockerfile与docker-compose的语法。

# 2025年1月7日

优化了之前的RVC，尝试在WSL中通过docker运行实现显卡直通，并push了自己的第一个image。

# 2025年1月12日

发现docker在pull的过程中时常出现有网络问题引起的报错，因此在Github上专门建立了一个private库，通过action的方式将docker hub上的镜像转到自己的阿里云镜像仓库中，以便拉取镜像的顺利。

# 2025年1月13日

在GitHub上冲浪的时候关注到了开源的ChatGLM4，然后花了两个晚上的时间去配环境(配环境真的是太快乐啦)，首次在自己的电脑上实现了本地LLM的部署，并对transformer有了一些初步的认识。

# 2025年1月15日

关注智谱和千问的同时发现了一个名为[CosyVoice](https://github.com/FunAudioLLM/CosyVoice)的项目，于是快速进行了环境配置与尝试，与之前搞的GPT-SoVITS比较后发现，CosyVoice的合成明显更快，而且省略了冗长的模型训练步骤，但是代价就是其合成效果较差。

# 2025年1月20日

由于读了差不多三个月的sEMG相关的论文，因此想要尝试一下自己动手实践一下。又因为听编程老师讲了最新的Yolo_v11，因此想要将基于sEMG的姿态识别和基于图像的姿态识别结合起来(然后首先开始的就是快乐的环境配置)。

# 2025年1月21号

为了实现sEMG信号的采集，搞了一块Arduino开发板和STM32开发板，然后捣鼓了几天Arduino、STM_Cube、Keil uVision5，~~然后把自己搞进了医院~~

# 2025年1月23日

为了更加便捷的学习Linux系统，在阿里云上购买了一台Ubuntu22.04的轻量应用服务器，通过Xshell与Xftp来实现在自己的电脑上通过终端操作服务器，通过Termius实现在其他安卓设备上访问服务器终端。

# 2025年1月25日

由于Yolo需要自己训练模型，但是自己的样本量小的可怜，最终导致模型效果极差，无可奈何之下选择了MediaPipe的现成的手势识别模型。不过在搞sEMG项目之余，还写了个程序尝试了一下使用MediaPipe实现手势操控光标执行左右键点击功能，效果还不错。

# 2025年1月26日

寻思着自己的服务器24小时开着必须做点什么有用的事情，于是通过Docker部署了一个Nextcloud网盘，虽然好像也没啥用处。

# 2025年1月27号

由于那段时间Deepseek的服务器时常出现故障，因此我决定结合之前的经验与[网上的一些教程](https://www.bilibili.com/video/BV1NGf2YtE8r)进行本地部署，采用gguf格式在Ollama与LMStudio上分别进行测试，最终采用了相对方便的LMStudio，部署了DeepSeek-R1-Distill-Llama-8B-Q8以及llama和qwen的一些版本进行测试比对。

# 2025年2月4号

还是寻思着自己的服务器24小时开着必须做点什么有用的事情，于是通过Docker部署了QQ机器人，并接入了Deepseek的API，勉强能用。

# 2025年2月7日

在我的第一个sEMG项目由于模型过拟合以及数据质量差的原因而宣告失败后，第一次使用git将我的项目push到GitHub上归档。

# 2025年2月8日

通过GitHub Page创建了自己的个人主页，最初使用jekyll来构建，当时还不会html、css、js，因此只是使用Markdown来完成第一个网页。

# 2025年2月11日

在B站上了解到Dify_ 之后，尝试着docker compose了一个，并将自己的Markdown格式的笔记导了进去，并搭建了几个用于学科回顾的工作流。

# 2025年2月15日

爬到了220万条书籍数据，想要实现快速检索，但是Access数据库根本带不动，于是尝试学习使用SQL Server Express来进行数据管理。

# 2025年2月16日

又寻思着自己的服务器24小时开着必须做点什么更加有用的事情，于是通过Docker部署了lobe-chat，不过在部署完之后发现自己像个傻子…… 然后就删了。

# 2025年2月19日

由于我的服务器内存太小，部署不了Dify_ ，因此通过Docker部署了N8N，但是很显然手感不如Dify_ ，现在只是挂着给同学用用，以后迟早会删了。

# 2025年2月20日

由于AI知识库对于Markdown格式的文件的解析效率更高，因此尝试通过文档解析和OCR等方式将其他文件格式转换为Markdown，于是在GitHub上面发现了这个库Anything2Markdown(不过现在好像找不到了)，实现了知识库的统一。

# 2025年2月21日

继Dify_之后，我又发现了RAGFlow这个专门用于知识库构建的应用，立即用Docker部署了一个试试，确实从各种程度上都远超其他同类型产品，只是在我自己电脑上跑的话还是太吃力了，然后删了。

# 2025年2月22日

由于QQ官方的机器人可操作性太差，于是我整了一个小号，在我的服务器上部署了NapCat，结合之前的Astrbot，成功实现了可以识别表情、发送表情包、主动应答、自由插话的拟人化程度较高的QQ机器人(和当初我们编程老师自己搞的大差不差)，然后第二天早上就被封号了:(

# 2025年2月23日

在GitHub上找到了几个开源的个人主页项目，于是边借鉴边学习搞出了[自己的第一个个人主页](https://turkeyc.github.io) (虽然大部分代码都是借鉴过来的)。

# 2025年2月24日

在此前的基础上，在没有借鉴其他人代码的情况下，完成了自己的[导航站](https://turkeyc.github.io/Navigation_Station)，并在后续不断地进行完善。

# 2025年2月26日

一直苦于我的电脑上无法运行安卓模拟器，一开始采用的是运行在docker中的安卓系统[docker-android](https://github.com/budtmo/docker-android)，但是性能很差，后来又[waydroid](https://waydro.id/)在WSL中运行，但是效果依旧不是很好，于是发现了[WSABuilds](https://github.com/MustardChef/WSABuilds)这个项目，最终以非ROOT版本结合ADB实现了在安卓子系统中的全自动挂机刷水课的目的。

# 2025年3月4日

终于成功搭建了我的[个人博客](https://turkeyc.github.io/Blog) (而且没有使用任何的博客网站模板，是纯手打的)！虽然还存在好多的Glitch需要去解决……

# 2025年3月10日

听了编程老师在班级群里的忽悠大为振奋，重新搞来了西瓜书，准备一个月学完🤗。